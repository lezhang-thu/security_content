{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 循环神经网络的从零开始实现\n",
    "\n",
    "## 独热编码\n",
    "\n",
    "* 选项一：每个词元都表示为一个数字索引\n",
    "* 选项二：更具表现力（more expressive）的特征向量\n",
    "* （批量大小，时间步数）\n",
    "* （时间步数，批量大小，词表大小）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 循环神经网络模型\n",
    "\n",
    "`init_rnn_state`函数\n",
    "\n",
    "```\n",
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), \n",
    "            device=device), )\n",
    "```\n",
    "\n",
    "为什么使用元组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "# `inputs` shape: \n",
    "# (`num_steps`, `batch_size`, `vocab_size`)\n",
    "# Shape of `X`: (`batch_size`, `vocab_size`)\n",
    "for X in inputs:\n",
    "    H = torch.tanh(torch.mm(X, W_xh) + torch.mm(\n",
    "                    H, W_hh) + b_h)\n",
    "    Y = torch.mm(H, W_hq) + b_q\n",
    "    outputs.append(Y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 41,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 梯度裁剪\n",
    "\n",
    "* 对于长度为$T$的序列，在迭代中计算这$T$个时间步上的梯度，将会在反向传播过程中产生长度为$\\mathcal{O}(T)$的矩阵乘法链\n",
    "* 当$T$较大时，它可能导致数值不稳定，例如可能导致梯度爆炸或梯度消失\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* *利普希茨连续的*（Lipschitz continuous）\n",
    "\n",
    "$$|f(\\mathbf{x}) - f(\\mathbf{y})| \\leq L \\|\\mathbf{x} - \\mathbf{y}\\|$$\n",
    "\n",
    "* 通过$\\eta \\mathbf{g}$更新参数向量\n",
    "\n",
    "$$|f(\\mathbf{x}) - f(\\mathbf{x} - \\eta\\mathbf{g})| \\leq L \\eta\\|\\mathbf{g}\\|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 将梯度$\\mathbf{g}$投影回给定半径（例如$\\theta$）的球\n",
    "\n",
    "$$\\mathbf{g} \\leftarrow \\min\\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}$$\n",
    "\n",
    "* 梯度范数永远不会超过$\\theta$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* the updated gradient is entirely aligned with the original direction of $\\mathbf{g}$\n",
    "* Gradient clipping provides a quick fix to the gradient exploding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 43,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "```\n",
    "norm = torch.sqrt(\n",
    "    sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "if norm > theta:\n",
    "    for param in params:\n",
    "        param.grad[:] *= theta / norm\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
