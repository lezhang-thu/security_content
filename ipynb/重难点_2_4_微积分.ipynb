{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 导数和微分\n",
    "\n",
    "* 在深度学习中，我们通常选择对于模型参数可微的损失函数\n",
    "* 简而言之，对于每个参数，如果我们把这个参数*增加*或*减少*一个无穷小的量，我们可以知道损失会以多快的速度增加或减少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "函数$f: \\mathbb{R} \\rightarrow \\mathbb{R}$\n",
    "\n",
    "$$f'(x) = \\lim_{h \\rightarrow 0} \\frac{f(x+h) - f(x)}{h}.$$\n",
    "\n",
    "* 如果$f'(a)$存在，则称$f$在$a$处是*可微*（differentiable）的\n",
    "* 如果$f$在一个区间内的每个数上都是可微的，则此函数在此区间中是可微的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 偏导数\n",
    "\n",
    "* 在深度学习中，函数通常依赖于许多变量\n",
    "* *多元函数*（multivariate function）\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$y$关于$x_i$的*偏导数*（partial derivative）为：\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial x_i} = \\lim_{h \\rightarrow 0} \\frac{f(x_1, \\ldots, x_{i-1}, x_i+h, x_{i+1}, \\ldots, x_n) - f(x_1, \\ldots, x_i, \\ldots, x_n)}{h}.$$\n",
    "\n",
    "为了计算$\\frac{\\partial y}{\\partial x_i}$，\n",
    "我们可以简单地将$x_1, \\ldots, x_{i-1}, x_{i+1}, \\ldots, x_n$看作常数，\n",
    "并计算$y$关于$x_i$的导数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 梯度\n",
    "\n",
    "* 函数$f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$\n",
    "* 函数$f(\\mathbf{x})$相对于$\\mathbf{x}$的梯度是一个包含$n$个偏导数的向量:\n",
    "\n",
    "$$\\nabla_{\\mathbf{x}} f(\\mathbf{x}) = \\bigg[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}, \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\mathbf{x})}{\\partial x_n}\\bigg]^T$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Derivative and gradient\n",
    "\n",
    "* $f:\\mathbb{R}^n\\to\\mathbb{R}^m$\n",
    "\n",
    "the *first-order approximation* of $f$ at (or near) $x$\n",
    "\n",
    "\\begin{equation*}\n",
    "    f(x)+Df(x)(z-x)\n",
    "\\end{equation*}\n",
    "\n",
    "* the shape of $Df(x)$ should be $\\mathbb{R}^{m\\times n}$\n",
    "* $D(f)_{ij}=\\tfrac{\\partial f_i(x)}{\\partial x_j}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* \n",
    "$$\\begin{equation*}\n",
    "    f(x)+\\nabla f(x)^T(z-x)\n",
    "\\end{equation*}$$\n",
    "\n",
    "* $\\nabla f(x)=Df(x)^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "假设$\\mathbf{x}$为$n$维向量，在微分多元函数时经常使用以下规则:\n",
    "\n",
    "* 对于所有$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$，都有$D \\mathbf{A} \\mathbf{x} = \\mathbf{A}$\n",
    "* 对于所有$\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$，那么$D \\mathbf{x}^T \\mathbf{A} \\mathbf{x}$为多少\n",
    "\n",
    "课堂思考提示：\n",
    "* 定义$\\mathbf{y}=\\mathbf{A}\\mathbf{x}$\n",
    "* $\\mathbf{x}^T \\mathbf{A} \\mathbf{x}=\\mathbf{x}^T \\mathbf{y}$\n",
    "* Product rule $(fg)'=f'g+fg'$\n",
    "* $\\mathbf{x}^T(\\mathbf{A}^T + \\mathbf{A})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $\\nabla_{\\mathbf{x}} \\|\\mathbf{x} \\|^2 = \\nabla_{\\mathbf{x}} \\mathbf{x}^T \\mathbf{x} = 2\\mathbf{x}$\n",
    "* 6\\_矩阵计算.pdf的第5页：样例\n",
    "\n",
    "注意$\\langle\\mathbf{u},\\mathbf{v}\\rangle=\\mathbf{u}^T\\mathbf{v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 练习\n",
    "\n",
    "7\\_自动求导.pdf的第2页：例子1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## 练习\n",
    "\n",
    "1. 求函数$f(\\mathbf{x}) = 3x_1^2 + 5e^{x_2}$的梯度。\n",
    "1. 函数$f(\\mathbf{x}) = \\|\\mathbf{x}\\|_2$的梯度是什么？\n",
    "\n",
    "提示：考虑$y=\\|\\mathbf{x}\\|^2$，所以，$f(\\mathbf{x})=\\sqrt{y}$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "幻灯片",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
