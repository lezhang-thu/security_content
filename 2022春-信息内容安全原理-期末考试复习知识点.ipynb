{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac99dbf6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 考试可能覆盖的知识点：\n",
    "\n",
    "1. 仅教材中的内容：\n",
    "    1. 2.1. 数据操作\n",
    "    1. 2.4.6. 练习\n",
    "    1. 3.4. softmax回归（可结合[2.9 logistic回归中的梯度下降法](https://www.bilibili.com/video/BV1FT4y1E74V?p=15)来帮助理解）\n",
    "    \n",
    "       （必考内容，请仔细复习）\n",
    "    1. 4.7. 前向传播、反向传播和计算图\n",
    "    1. 6.1. 从全连接层到卷积\n",
    "    1. 6.3. 填充和步幅\n",
    "    1. 6.4. 多输入多输出通道\n",
    "    1. 7.2. 使用块的网络（VGG）\n",
    "\n",
    "1. 需结合课件复习的内容：\n",
    "\n",
    "    1. 结合anchor.ipynb（课件），阅读：13.4. 锚框（必考内容，请仔细复习）\n",
    "    1. 结合multiscale-object-detection.ipynb（课件），阅读：13.5. 多尺度目标检测\n",
    "    1. 结合ssd.ipynb（课件），阅读：13.7. 单发多框检测（SSD）\n",
    "    1. 结合transposed-conv.ipynb（课件），阅读：13.10. 转置卷积\n",
    "    1. 结合sequence.ipynb（课件），阅读：8.1. 序列模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba61803",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 考试复习题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2562874e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. 计算sigmoid函数的导数：\n",
    "\n",
    "    $$\n",
    "    \\sigma(x)=\\frac{1}{1+e^{-x}}\\in (0,1)\n",
    "    $$\n",
    "\n",
    "1. 考虑如下的神经网络结构：\n",
    "\n",
    "    ```\n",
    "    self.net = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(3, 32, kernel_size=7, \n",
    "                        padding=2),\n",
    "        torch.nn.BatchNorm2d(32),\n",
    "        torch.nn.MaxPool2d(2, 2),\n",
    "        torch.nn.MaxPool2d(2, 2),)\n",
    "    ```\n",
    "   \n",
    "   给定`x = torch.rand(1, 3, 224, 224)`，请问`self.net(x)`的输出张量的形状是怎样的，请同时给出详细的分析过程。\n",
    "\n",
    "1. 给定一个63x63x16的输入，并使用大小为7x7的32个卷积核进行卷积（步幅为2和无填充），请问输出是多少，为什么。\n",
    "1. 给定输入的张量，形状为64x64x16，请问作用于其上的单个1x1的卷积核含有多少个参数（包括bias），为什么。\n",
    "1. 给定如下的卷积神经网络结构：\n",
    "    * 输入：RGB图像，高宽为$256\\times 256$\n",
    "    * 第1层为：32个卷积核，大小为$3\\times 3$，步幅为1，padding为1\n",
    "    * 第2层为：一个最大池化层，大小为$2\\times 2$，步幅为2\n",
    "   \n",
    "   请问输出中的每个单元在输入上的感受野为多少，为什么。\n",
    "1. 考虑如下的单隐藏层神经网络，其用于进行二分类的任务。输入为$X\\in\\mathbb{R}^{n\\times m}$，输出为$\\hat{y}\\in \\mathbb{R}^{1\\times m}$，而真实的标签为$y\\in \\mathbb{R}^{1\\times m}$.前向传播的公式如下：\n",
    "\n",
    "    \\begin{align*}\n",
    "    z^{[1]}&=W^{[1]}X+b^{[1]}\\\\\n",
    "    a^{[1]}&=\\sigma(z^{[1]}\\\\\n",
    "    \\hat{y}&=a^{[1]}\\\\\n",
    "    \\mathcal{J}&=-\\sum_{i=1}^m \\bigl( y^{(i)}\\log \\hat{y}^{(i)}+(1-y^{(i)})\\log (1-\\hat{y}^{(i)})\\bigr)\n",
    "    \\end{align*}\n",
    "\n",
    "   请以两个矩阵相乘的形式写出$\\tfrac{\\partial \\mathcal{J}}{\\partial W^{[1]}}$的表达式。\n",
    "1. 你在设计一个卷积神经网络。对于每一层，请计算weights的个数，biases的个数，以及相应的特征图的大小。\n",
    "   \n",
    "   相关符号的含义如下：\n",
    "   * CONV-K-N表示卷积核的个数为N，每个卷积核的大小为KxK，填充和步幅分别为0和1；\n",
    "   * POOL-K表示一个KxK的池化层，步幅为K，填充为0；\n",
    "   * FC-N表示一个全连接层，有N个神经元。\n",
    "       \n",
    "| Layer     | Activation map dimensions  | Number of weights  | Number of biases  |\n",
    "| :----:    |  :-----------------------: | :----------------: | :--------------:  |\n",
    "| INPUT     |  128x128x3                 |         0          |           0       |\n",
    "| CONV-9-32 |                            |                    |                   |\n",
    "| POOL-2    |                            |                    |                   |\n",
    "| CONV-5-64 |                            |                    |                   |\n",
    "| POOL-2    |                            |                    |                   |\n",
    "| CONV-5-64 |                            |                    |                   |\n",
    "| POOL-2    |                            |                    |                   |\n",
    "| FC-3      |                            |                    |                   |\n",
    "\n",
    "\n",
    "1. 现在需要你帮忙解决一个分类问题。首先，你在一个仅20个样本的数据集上进行了训练。训练是收敛的，但是，训练的损失函数值非常高。\n",
    "   \n",
    "   你决定在更多的样本（10,000个）上重新训练之前的模型。\n",
    "   \n",
    "   请问这样做可以解决上述问题吗：\n",
    "   * 如果能，请解释在10,000个样本上训练最有可能得到的结果；\n",
    "   * 如果不能，请给出一个新的解决方案。\n",
    "   \n",
    "1. 非极大值抑制是一种贪心算法，它通过移除来抑制预测的边界框。是否存在一种可能，被移除的一些框实际上是有用的？如何修改这个算法来柔和地抑制？你可以参考Soft-NMS。\n",
    "\n",
    "   [1] Bodla, Navaneeth, et al. \"Soft-NMS--improving object detection with one line of code.\" Proceedings of the IEEE international conference on computer vision. 2017.\n",
    "   \n",
    "1. 构建并可视化两个IoU为0.5的边界框。它们是怎样重叠的？"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
